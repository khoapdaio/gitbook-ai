# ğŸ“’ Thuáº­t ngá»¯

BÃªn dÆ°á»›i lÃ  báº£ng cÃ¡c thuáº­t ngá»¯ kÃ¨m theo Ã½ nghÄ©a Ä‘Æ°á»£c sá»­ dá»¥ng trong cuá»‘n sÃ¡ch. CÃ¡c thuáº­t ngá»¯ nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c dá»‹ch ra Tiáº¿ng Viá»‡t hoáº·c giá»¯a nguyÃªn gá»‘c Tiáº¿ng Anh kÃ¨m theo giáº£i thÃ­ch Ã½ nghÄ©a náº¿u khÃ´ng tÃ¬m Ä‘Æ°á»£c dá»‹ch nghÄ©a Tiáº¿ng Viá»‡t phÃ¹ há»£p.

<table data-full-width="true"><thead><tr><th width="226">Thuáº­t ngá»¯ (tiáº¿ng Anh)</th><th width="226">Dá»‹ch nghÄ©a (tiáº¿ng Viá»‡t)</th><th width="398">Ã nghÄ©a</th></tr></thead><tbody><tr><td>Artificial Intelligence (AI)</td><td>TrÃ­ tuá»‡ nhÃ¢n táº¡o</td><td>Kháº£ nÄƒng cá»§a mÃ¡y mÃ³c mÃ´ phá»ng trÃ­ tuá»‡ con ngÆ°á»i.</td></tr><tr><td>Machine Learning (ML)</td><td>Há»c mÃ¡y</td><td>Má»™t nhÃ¡nh cá»§a AI, nÆ¡i mÃ¡y há»c tá»« dá»¯ liá»‡u Ä‘á»ƒ Ä‘Æ°a ra dá»± Ä‘oÃ¡n hoáº·c quyáº¿t Ä‘á»‹nh.</td></tr><tr><td>Deep Learning</td><td>Há»c sÃ¢u</td><td>Má»™t táº­p con cá»§a há»c mÃ¡y sá»­ dá»¥ng máº¡ng nÆ¡-ron vá»›i nhiá»u táº§ng.</td></tr><tr><td>Neural Network</td><td>Máº¡ng nÆ¡-ron</td><td>Há»‡ thá»‘ng mÃ´ phá»ng cáº¥u trÃºc cá»§a nÃ£o ngÆ°á»i Ä‘á»ƒ xá»­ lÃ½ dá»¯ liá»‡u.</td></tr><tr><td>Supervised Learning</td><td>Há»c cÃ³ giÃ¡m sÃ¡t</td><td>PhÆ°Æ¡ng phÃ¡p há»c mÃ¡y sá»­ dá»¥ng dá»¯ liá»‡u Ä‘Ã£ gÃ¡n nhÃ£n Ä‘á»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh.</td></tr><tr><td>Unsupervised Learning</td><td>Há»c khÃ´ng giÃ¡m sÃ¡t</td><td>PhÆ°Æ¡ng phÃ¡p há»c mÃ¡y tÃ¬m kiáº¿m cáº¥u trÃºc trong dá»¯ liá»‡u khÃ´ng cÃ³ nhÃ£n.</td></tr><tr><td>Reinforcement Learning</td><td>Há»c tÄƒng cÆ°á»ng</td><td>Ká»¹ thuáº­t há»c mÃ¡y dá»±a trÃªn pháº§n thÆ°á»Ÿng vÃ  hÃ¬nh pháº¡t Ä‘á»ƒ tá»‘i Æ°u hÃ nh Ä‘á»™ng.</td></tr><tr><td>Overfitting</td><td>QuÃ¡ khá»›p</td><td>Khi mÃ´ hÃ¬nh há»c quÃ¡ nhiá»u tá»« dá»¯ liá»‡u huáº¥n luyá»‡n vÃ  kÃ©m trÃªn dá»¯ liá»‡u má»›i.</td></tr><tr><td>Underfitting</td><td>ChÆ°a khá»›p</td><td>Khi mÃ´ hÃ¬nh chÆ°a há»c Ä‘á»§ Ä‘á»ƒ biá»ƒu diá»…n dá»¯ liá»‡u.</td></tr><tr><td>Feature Engineering</td><td>Xá»­ lÃ½ Ä‘áº·c trÆ°ng</td><td>QuÃ¡ trÃ¬nh chá»n lá»c vÃ  biáº¿n Ä‘á»•i dá»¯ liá»‡u Ä‘áº§u vÃ o Ä‘á»ƒ cáº£i thiá»‡n hiá»‡u suáº¥t.</td></tr><tr><td>Gradient Descent</td><td>Giáº£m Ä‘á»™ dá»‘c</td><td>Thuáº­t toÃ¡n tá»‘i Æ°u hÃ³a Ä‘á»ƒ tÃ¬m cá»±c tiá»ƒu cá»§a má»™t hÃ m sá»‘.</td></tr><tr><td>Activation Function</td><td>HÃ m kÃ­ch hoáº¡t</td><td>HÃ m toÃ¡n há»c Ä‘Æ°á»£c sá»­ dá»¥ng trong máº¡ng nÆ¡-ron Ä‘á»ƒ quyáº¿t Ä‘á»‹nh Ä‘áº§u ra cá»§a nÃºt.</td></tr><tr><td>Backpropagation</td><td>Lan truyá»n ngÆ°á»£c</td><td>Thuáº­t toÃ¡n tá»‘i Æ°u hÃ³a trá»ng sá»‘ trong máº¡ng nÆ¡-ron báº±ng cÃ¡ch tÃ­nh gradient.</td></tr><tr><td>Epoch</td><td>Ká»· nguyÃªn</td><td>Má»™t vÃ²ng láº·p qua toÃ n bá»™ dá»¯ liá»‡u huáº¥n luyá»‡n trong quÃ¡ trÃ¬nh há»c.</td></tr><tr><td>Batch</td><td>LÃ´</td><td>Má»™t pháº§n nhá» cá»§a dá»¯ liá»‡u Ä‘Æ°á»£c sá»­ dá»¥ng trong má»—i láº§n huáº¥n luyá»‡n.</td></tr><tr><td>Loss Function</td><td>HÃ m máº¥t mÃ¡t</td><td>HÃ m sá»‘ Ä‘o lÆ°á»ng sá»± khÃ¡c biá»‡t giá»¯a dá»± Ä‘oÃ¡n cá»§a mÃ´ hÃ¬nh vÃ  giÃ¡ trá»‹ thá»±c.</td></tr><tr><td>Natural Language Processing (NLP)</td><td>Xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn</td><td>Má»™t nhÃ¡nh cá»§a AI táº­p trung vÃ o xá»­ lÃ½ vÃ  hiá»ƒu dá»¯ liá»‡u ngÃ´n ngá»¯ con ngÆ°á»i.</td></tr><tr><td>Computer Vision</td><td>Thá»‹ giÃ¡c mÃ¡y tÃ­nh</td><td>Má»™t nhÃ¡nh cá»§a AI giÃºp mÃ¡y mÃ³c "nhÃ¬n" vÃ  phÃ¢n tÃ­ch hÃ¬nh áº£nh, video.</td></tr><tr><td>Generative Model</td><td>MÃ´ hÃ¬nh táº¡o sinh</td><td>MÃ´ hÃ¬nh AI táº¡o ra dá»¯ liá»‡u má»›i tá»« dá»¯ liá»‡u Ä‘Ã£ há»c.</td></tr><tr><td>Transfer Learning</td><td>Há»c chuyá»ƒn giao</td><td>Ká»¹ thuáº­t há»c mÃ¡y sá»­ dá»¥ng kiáº¿n thá»©c tá»« má»™t nhiá»‡m vá»¥ Ä‘á»ƒ Ã¡p dá»¥ng cho nhiá»‡m vá»¥ khÃ¡c.</td></tr><tr><td>Convolutional Neural Network (CNN)</td><td>Máº¡ng nÆ¡-ron tÃ­ch cháº­p</td><td>Má»™t loáº¡i máº¡ng nÆ¡-ron thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng trong xá»­ lÃ½ hÃ¬nh áº£nh.</td></tr><tr><td>Recurrent Neural Network (RNN)</td><td>Máº¡ng nÆ¡-ron há»“i tiáº¿p</td><td>Má»™t loáº¡i máº¡ng nÆ¡-ron xá»­ lÃ½ dá»¯ liá»‡u tuáº§n tá»± nhÆ° vÄƒn báº£n, Ã¢m thanh.</td></tr><tr><td>Generative Adversarial Network (GAN)</td><td>Máº¡ng Ä‘á»‘i khÃ¡ng sinh</td><td>Há»‡ thá»‘ng gá»“m hai máº¡ng nÆ¡-ron cáº¡nh tranh nhau Ä‘á»ƒ cáº£i thiá»‡n hiá»‡u quáº£ sinh dá»¯ liá»‡u.</td></tr><tr><td>Hyperparameter</td><td>SiÃªu tham sá»‘</td><td>Tham sá»‘ Ä‘Æ°á»£c thiáº¿t láº­p trÆ°á»›c khi huáº¥n luyá»‡n mÃ´ hÃ¬nh, nhÆ° tá»‘c Ä‘á»™ há»c.</td></tr><tr><td>Dropout</td><td>Ká»¹ thuáº­t dropout</td><td>PhÆ°Æ¡ng phÃ¡p giáº£m quÃ¡ khá»›p báº±ng cÃ¡ch ngáº¯t má»™t sá»‘ nÃºt trong máº¡ng nÆ¡-ron.</td></tr><tr><td>Ensemble Learning</td><td>Há»c táº­p há»£p</td><td>PhÆ°Æ¡ng phÃ¡p káº¿t há»£p nhiá»u mÃ´ hÃ¬nh Ä‘á»ƒ cáº£i thiá»‡n hiá»‡u suáº¥t.</td></tr><tr><td>Stochastic Gradient Descent (SGD)</td><td>Thuáº­t toÃ¡n SGD</td><td>Má»™t biáº¿n thá»ƒ cá»§a giáº£m Ä‘á»™ dá»‘c, cáº­p nháº­t trá»ng sá»‘ theo tá»«ng máº«u dá»¯ liá»‡u.</td></tr><tr><td>Softmax Function</td><td>HÃ m softmax</td><td>HÃ m toÃ¡n há»c chuyá»ƒn Ä‘á»•i Ä‘áº§u ra thÃ nh xÃ¡c suáº¥t.</td></tr><tr><td>Cross-Entropy Loss</td><td>HÃ m máº¥t mÃ¡t cross-entropy</td><td>HÃ m máº¥t mÃ¡t thÆ°á»ng dÃ¹ng trong phÃ¢n loáº¡i Ä‘a lá»›p.</td></tr><tr><td>One-Hot Encoding</td><td>MÃ£ hÃ³a one-hot</td><td>PhÆ°Æ¡ng phÃ¡p biá»ƒu diá»…n cÃ¡c danh má»¥c thÃ nh cÃ¡c vector nhá»‹ phÃ¢n.</td></tr><tr><td>Dimensionality Reduction</td><td>Giáº£m chiá»u dá»¯ liá»‡u</td><td>QuÃ¡ trÃ¬nh giáº£m sá»‘ lÆ°á»£ng Ä‘áº·c trÆ°ng cá»§a dá»¯ liá»‡u Ä‘á»ƒ Ä‘Æ¡n giáº£n hÃ³a mÃ´ hÃ¬nh.</td></tr><tr><td>Principal Component Analysis (PCA)</td><td>PhÃ¢n tÃ­ch thÃ nh pháº§n chÃ­nh</td><td>PhÆ°Æ¡ng phÃ¡p giáº£m chiá»u dá»¯ liá»‡u phá»• biáº¿n trong há»c mÃ¡y.</td></tr><tr><td>Long Short-Term Memory (LSTM)</td><td>Bá»™ nhá»› ngáº¯n dÃ i háº¡n</td><td>Má»™t loáº¡i máº¡ng nÆ¡-ron há»“i tiáº¿p cáº£i tiáº¿n Ä‘á»ƒ xá»­ lÃ½ chuá»—i dá»¯ liá»‡u dÃ i.</td></tr><tr><td>Attention Mechanism</td><td>CÆ¡ cháº¿ chÃº Ã½</td><td>Ká»¹ thuáº­t cáº£i tiáº¿n hiá»‡u quáº£ xá»­ lÃ½ chuá»—i báº±ng cÃ¡ch táº­p trung vÃ o thÃ´ng tin quan trá»ng.</td></tr><tr><td>Transformer</td><td>MÃ´ hÃ¬nh Transformer</td><td>Kiáº¿n trÃºc AI phá»• biáº¿n trong xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn, nhÆ° BERT, GPT.</td></tr><tr><td>Word Embedding</td><td>NhÃºng tá»«</td><td>PhÆ°Æ¡ng phÃ¡p biá»ƒu diá»…n tá»« ngá»¯ dÆ°á»›i dáº¡ng vector sá»‘.</td></tr><tr><td>Clustering</td><td>PhÃ¢n cá»¥m</td><td>Ká»¹ thuáº­t nhÃ³m cÃ¡c dá»¯ liá»‡u thÃ nh cÃ¡c cá»¥m dá»±a trÃªn Ä‘áº·c Ä‘iá»ƒm tÆ°Æ¡ng Ä‘á»“ng.</td></tr><tr><td>K-Nearest Neighbors (KNN)</td><td>PhÆ°Æ¡ng phÃ¡p K lÃ¡ng giá»ng gáº§n nháº¥t</td><td>Thuáº­t toÃ¡n há»c mÃ¡y dá»±a trÃªn khoáº£ng cÃ¡ch giá»¯a cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u.</td></tr><tr><td>Decision Tree</td><td>CÃ¢y quyáº¿t Ä‘á»‹nh</td><td>MÃ´ hÃ¬nh dá»± Ä‘oÃ¡n dá»±a trÃªn cáº¥u trÃºc cÃ¢y Ä‘á»ƒ Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh.</td></tr><tr><td>Random Forest</td><td>Rá»«ng ngáº«u nhiÃªn</td><td>Táº­p há»£p nhiá»u cÃ¢y quyáº¿t Ä‘á»‹nh Ä‘á»ƒ cáº£i thiá»‡n hiá»‡u suáº¥t.</td></tr><tr><td>Support Vector Machine (SVM)</td><td>MÃ¡y vector há»— trá»£</td><td>Thuáº­t toÃ¡n phÃ¢n loáº¡i tá»‘i Æ°u hÃ³a ranh giá»›i giá»¯a cÃ¡c lá»›p.</td></tr><tr><td>F1 Score</td><td>Äiá»ƒm F1</td><td>ThÆ°á»›c Ä‘o hiá»‡u suáº¥t mÃ´ hÃ¬nh, cÃ¢n báº±ng giá»¯a Precision vÃ  Recall.</td></tr><tr><td>Confusion Matrix</td><td>Ma tráº­n nháº§m láº«n</td><td>Báº£ng Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t mÃ´ hÃ¬nh phÃ¢n loáº¡i dá»±a trÃªn dá»± Ä‘oÃ¡n vÃ  giÃ¡ trá»‹ thá»±c.</td></tr></tbody></table>
