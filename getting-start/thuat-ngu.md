# 📒 Thuật ngữ

Bên dưới là bảng các thuật ngữ kèm theo ý nghĩa được sử dụng trong cuốn sách. Các thuật ngữ này có thể được dịch ra Tiếng Việt hoặc giữa nguyên gốc Tiếng Anh kèm theo giải thích ý nghĩa nếu không tìm được dịch nghĩa Tiếng Việt phù hợp.

<table data-full-width="true"><thead><tr><th width="226">Thuật ngữ (tiếng Anh)</th><th width="226">Dịch nghĩa (tiếng Việt)</th><th width="398">Ý nghĩa</th></tr></thead><tbody><tr><td>Artificial Intelligence (AI)</td><td>Trí tuệ nhân tạo</td><td>Khả năng của máy móc mô phỏng trí tuệ con người.</td></tr><tr><td>Machine Learning (ML)</td><td>Học máy</td><td>Một nhánh của AI, nơi máy học từ dữ liệu để đưa ra dự đoán hoặc quyết định.</td></tr><tr><td>Deep Learning</td><td>Học sâu</td><td>Một tập con của học máy sử dụng mạng nơ-ron với nhiều tầng.</td></tr><tr><td>Neural Network</td><td>Mạng nơ-ron</td><td>Hệ thống mô phỏng cấu trúc của não người để xử lý dữ liệu.</td></tr><tr><td>Supervised Learning</td><td>Học có giám sát</td><td>Phương pháp học máy sử dụng dữ liệu đã gán nhãn để huấn luyện mô hình.</td></tr><tr><td>Unsupervised Learning</td><td>Học không giám sát</td><td>Phương pháp học máy tìm kiếm cấu trúc trong dữ liệu không có nhãn.</td></tr><tr><td>Reinforcement Learning</td><td>Học tăng cường</td><td>Kỹ thuật học máy dựa trên phần thưởng và hình phạt để tối ưu hành động.</td></tr><tr><td>Overfitting</td><td>Quá khớp</td><td>Khi mô hình học quá nhiều từ dữ liệu huấn luyện và kém trên dữ liệu mới.</td></tr><tr><td>Underfitting</td><td>Chưa khớp</td><td>Khi mô hình chưa học đủ để biểu diễn dữ liệu.</td></tr><tr><td>Feature Engineering</td><td>Xử lý đặc trưng</td><td>Quá trình chọn lọc và biến đổi dữ liệu đầu vào để cải thiện hiệu suất.</td></tr><tr><td>Gradient Descent</td><td>Giảm độ dốc</td><td>Thuật toán tối ưu hóa để tìm cực tiểu của một hàm số.</td></tr><tr><td>Activation Function</td><td>Hàm kích hoạt</td><td>Hàm toán học được sử dụng trong mạng nơ-ron để quyết định đầu ra của nút.</td></tr><tr><td>Backpropagation</td><td>Lan truyền ngược</td><td>Thuật toán tối ưu hóa trọng số trong mạng nơ-ron bằng cách tính gradient.</td></tr><tr><td>Epoch</td><td>Kỷ nguyên</td><td>Một vòng lặp qua toàn bộ dữ liệu huấn luyện trong quá trình học.</td></tr><tr><td>Batch</td><td>Lô</td><td>Một phần nhỏ của dữ liệu được sử dụng trong mỗi lần huấn luyện.</td></tr><tr><td>Loss Function</td><td>Hàm mất mát</td><td>Hàm số đo lường sự khác biệt giữa dự đoán của mô hình và giá trị thực.</td></tr><tr><td>Natural Language Processing (NLP)</td><td>Xử lý ngôn ngữ tự nhiên</td><td>Một nhánh của AI tập trung vào xử lý và hiểu dữ liệu ngôn ngữ con người.</td></tr><tr><td>Computer Vision</td><td>Thị giác máy tính</td><td>Một nhánh của AI giúp máy móc "nhìn" và phân tích hình ảnh, video.</td></tr><tr><td>Generative Model</td><td>Mô hình tạo sinh</td><td>Mô hình AI tạo ra dữ liệu mới từ dữ liệu đã học.</td></tr><tr><td>Transfer Learning</td><td>Học chuyển giao</td><td>Kỹ thuật học máy sử dụng kiến thức từ một nhiệm vụ để áp dụng cho nhiệm vụ khác.</td></tr><tr><td>Convolutional Neural Network (CNN)</td><td>Mạng nơ-ron tích chập</td><td>Một loại mạng nơ-ron thường được sử dụng trong xử lý hình ảnh.</td></tr><tr><td>Recurrent Neural Network (RNN)</td><td>Mạng nơ-ron hồi tiếp</td><td>Một loại mạng nơ-ron xử lý dữ liệu tuần tự như văn bản, âm thanh.</td></tr><tr><td>Generative Adversarial Network (GAN)</td><td>Mạng đối kháng sinh</td><td>Hệ thống gồm hai mạng nơ-ron cạnh tranh nhau để cải thiện hiệu quả sinh dữ liệu.</td></tr><tr><td>Hyperparameter</td><td>Siêu tham số</td><td>Tham số được thiết lập trước khi huấn luyện mô hình, như tốc độ học.</td></tr><tr><td>Dropout</td><td>Kỹ thuật dropout</td><td>Phương pháp giảm quá khớp bằng cách ngắt một số nút trong mạng nơ-ron.</td></tr><tr><td>Ensemble Learning</td><td>Học tập hợp</td><td>Phương pháp kết hợp nhiều mô hình để cải thiện hiệu suất.</td></tr><tr><td>Stochastic Gradient Descent (SGD)</td><td>Thuật toán SGD</td><td>Một biến thể của giảm độ dốc, cập nhật trọng số theo từng mẫu dữ liệu.</td></tr><tr><td>Softmax Function</td><td>Hàm softmax</td><td>Hàm toán học chuyển đổi đầu ra thành xác suất.</td></tr><tr><td>Cross-Entropy Loss</td><td>Hàm mất mát cross-entropy</td><td>Hàm mất mát thường dùng trong phân loại đa lớp.</td></tr><tr><td>One-Hot Encoding</td><td>Mã hóa one-hot</td><td>Phương pháp biểu diễn các danh mục thành các vector nhị phân.</td></tr><tr><td>Dimensionality Reduction</td><td>Giảm chiều dữ liệu</td><td>Quá trình giảm số lượng đặc trưng của dữ liệu để đơn giản hóa mô hình.</td></tr><tr><td>Principal Component Analysis (PCA)</td><td>Phân tích thành phần chính</td><td>Phương pháp giảm chiều dữ liệu phổ biến trong học máy.</td></tr><tr><td>Long Short-Term Memory (LSTM)</td><td>Bộ nhớ ngắn dài hạn</td><td>Một loại mạng nơ-ron hồi tiếp cải tiến để xử lý chuỗi dữ liệu dài.</td></tr><tr><td>Attention Mechanism</td><td>Cơ chế chú ý</td><td>Kỹ thuật cải tiến hiệu quả xử lý chuỗi bằng cách tập trung vào thông tin quan trọng.</td></tr><tr><td>Transformer</td><td>Mô hình Transformer</td><td>Kiến trúc AI phổ biến trong xử lý ngôn ngữ tự nhiên, như BERT, GPT.</td></tr><tr><td>Word Embedding</td><td>Nhúng từ</td><td>Phương pháp biểu diễn từ ngữ dưới dạng vector số.</td></tr><tr><td>Clustering</td><td>Phân cụm</td><td>Kỹ thuật nhóm các dữ liệu thành các cụm dựa trên đặc điểm tương đồng.</td></tr><tr><td>K-Nearest Neighbors (KNN)</td><td>Phương pháp K láng giềng gần nhất</td><td>Thuật toán học máy dựa trên khoảng cách giữa các điểm dữ liệu.</td></tr><tr><td>Decision Tree</td><td>Cây quyết định</td><td>Mô hình dự đoán dựa trên cấu trúc cây để đưa ra quyết định.</td></tr><tr><td>Random Forest</td><td>Rừng ngẫu nhiên</td><td>Tập hợp nhiều cây quyết định để cải thiện hiệu suất.</td></tr><tr><td>Support Vector Machine (SVM)</td><td>Máy vector hỗ trợ</td><td>Thuật toán phân loại tối ưu hóa ranh giới giữa các lớp.</td></tr><tr><td>F1 Score</td><td>Điểm F1</td><td>Thước đo hiệu suất mô hình, cân bằng giữa Precision và Recall.</td></tr><tr><td>Confusion Matrix</td><td>Ma trận nhầm lẫn</td><td>Bảng đánh giá hiệu suất mô hình phân loại dựa trên dự đoán và giá trị thực.</td></tr></tbody></table>
