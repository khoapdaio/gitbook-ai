# Ph√©p bi·∫øn ƒë·ªïi tuy·∫øn t√≠nh

## 1. Kh√°i ni·ªám c∆° b·∫£n

Ph√©p bi·∫øn ƒë·ªïi tuy·∫øn t√≠nh l√† √°nh x·∫° t·ª´ m·ªôt kh√¥ng gian vector sang kh√¥ng gian vector kh√°c, duy tr√¨ c√°c t√≠nh ch·∫•t c·ªßa ph√©p c·ªông v√† ph√©p nh√¢n v·ªõi m·ªôt s·ªë th·ª±c:

$$
T(a‚ãÖv+b‚ãÖu)=a‚ãÖT(v)+b‚ãÖT(u)
$$

v·ªõi ùëé , ùëè l√† h·∫±ng s·ªë, ùë£ , ùë¢  l√† vector.

**·ª®ng d·ª•ng**:

* Bi·ªÉu di·ªÖn c√°c ph√©p quay, co d√£n, ph·∫£n chi·∫øu, v√† chuy·ªÉn v·ªã trong kh√¥ng gian.
* Gi·∫£m s·ªë chi·ªÅu trong PCA ho·∫∑c embedding.
* Bi·∫øn ƒë·ªïi d·ªØ li·ªáu ƒë·∫ßu v√†o trong c√°c m√¥ h√¨nh h·ªçc m√°y.

***

## 2. C√°c ph√©p bi·∫øn ƒë·ªïi c∆° b·∫£n

### 2.1 Ph√©p quay (Rotation)

**Ph√©p quay (Rotation)** l√† m·ªôt ph√©p bi·∫øn ƒë·ªïi h√¨nh h·ªçc xoay c√°c ƒëi·ªÉm quanh m·ªôt ƒëi·ªÉm g·ªëc ho·∫∑c m·ªôt tr·ª•c c·ªë ƒë·ªãnh, v·ªõi m·ªôt g√≥c quay x√°c ƒë·ªãnh. Trong kh√¥ng gian hai chi·ªÅu, ph√©p quay quanh g·ªëc t·ªça ƒë·ªô ƒë∆∞·ª£c bi·ªÉu di·ªÖn b·∫±ng ma tr·∫≠n xoay, chuy·ªÉn ƒë·ªïi t·ªça ƒë·ªô c·ªßa m·ªôt vector b·∫±ng c√¥ng th·ª©c to√°n h·ªçc. Ph√©p quay b·∫£o to√†n kho·∫£ng c√°ch gi·ªØa c√°c ƒëi·ªÉm v√† h√¨nh d√°ng c·ªßa h√¨nh h·ªçc ban ƒë·∫ßu.

> Ph√©p quay (Rotation) l√† m·ªôt ph√©p bi·∫øn ƒë·ªïi vector trong kh√¥ng gian b·∫±ng c√°ch quay n√≥ m·ªôt g√≥c ùúÉ Œ∏ quanh g·ªëc t·ªça ƒë·ªô.

**Ma tr·∫≠n quay** trong 2D:

$$
A=\begin{bmatrix}cos(\theta)&-sin(\theta)\cr sin(\theta)&cos(\theta)\end{bmatrix}
$$

{% tabs %}
{% tab title="Pytorch" %}
```python
import torch

theta_torch = torch.tensor(np.pi / 4)
rotation_matrix_torch = torch.tensor([[torch.cos(theta_torch), -torch.sin(theta_torch)],
                                       [torch.sin(theta_torch),  torch.cos(theta_torch)]])
                                       
vector_torch = torch.tensor([1, 0], dtype=torch.float32)
rotated_vector_torch = torch.matmul(rotation_matrix_torch, vector_torch)

print("\nPyTorch Rotated Vector:\n", rotated_vector_torch)
```
{% endtab %}

{% tab title="Numpy" %}
```python
import numpy as np

theta = np.pi / 4  # 45 degrees
rotation_matrix = np.array([[np.cos(theta), -np.sin(theta)],
                            [np.sin(theta),  np.cos(theta)]])
vector = np.array([1, 0])
rotated_vector = np.dot(rotation_matrix, vector)
print("NumPy Rotated Vector:\n", rotated_vector)
```
{% endtab %}
{% endtabs %}

### 2.2 Ph√©p co d√£n (Scaling)

### 2.2 Ph√©p co d√£n (Scaling)

Ph√©p co d√£n (Scaling) l√† m·ªôt ph√©p bi·∫øn ƒë·ªïi h√¨nh h·ªçc thay ƒë·ªïi k√≠ch th∆∞·ªõc c·ªßa m·ªôt vector ho·∫∑c h√¨nh trong kh√¥ng gian m√† kh√¥ng l√†m thay ƒë·ªïi h√¨nh d·∫°ng c·ªßa n√≥. Trong kh√¥ng gian 2D, ph√©p co d√£n c√≥ th·ªÉ ƒë∆∞·ª£c th·ª±c hi·ªán b·∫±ng c√°ch nh√¢n c√°c t·ªça ƒë·ªô c·ªßa c√°c ƒëi·ªÉm v·ªõi c√°c h·ªá s·ªë t·ª∑ l·ªá tr√™n c√°c tr·ª•c t·ªça ƒë·ªô.

> &#x20;Ph√©p co d√£n l√† ph√©p thay ƒë·ªïi k√≠ch th∆∞·ªõc c·ªßa vector theo m·ªôt t·ªâ l·ªá ùë† s

**Ma tr·∫≠n co d√£n**

$$
A=\begin{bmatrix}S_x&0\cr 0&S_y\end{bmatrix}
$$

{% tabs %}
{% tab title="Pytorch" %}
```python
import torch


scaling_matrix_torch = torch.tensor([[2, 0], [0, 3]])
vector_torch = torch.tensor([1, 1], dtype=torch.float32)
scaled_vector_torch = torch.matmul(scaling_matrix_torch, vector_torch)

print("\nPyTorch Scaled Vector:\n", scaled_vector_torch)
```
{% endtab %}

{% tab title="Numpy" %}
```python
import numpy as np

scaling_matrix = np.array([[2, 0], [0, 3]])  # Scale by 2 in x, 3 in y
vector = np.array([1, 1])
scaled_vector = np.dot(scaling_matrix, vector)

print("NumPy Scaled Vector:\n", scaled_vector)
```
{% endtab %}
{% endtabs %}

### 2.3 Ph√©p ph·∫£n chi·∫øu (Reflection)

Ph√©p ph·∫£n chi·∫øu l√† ph√©p bi·∫øn ƒë·ªïi √°nh x·∫° m·ªói ƒëi·ªÉm c·ªßa ƒë·ªëi t∆∞·ª£ng ƒë·∫øn ƒëi·ªÉm ƒë·ªëi x·ª©ng qua tr·ª•c ho·∫∑c m·∫∑t ph·∫≥ng.

> Ph·∫£n chi·∫øu vector qua m·ªôt tr·ª•c ho·∫∑c m·∫∑t ph·∫≥ng.

#### Ma tr·∫≠n ph·∫£n chi·∫øu qua tr·ª•c x:

$$
R=\begin{bmatrix}1&0\cr 0&-1\end{bmatrix}
$$

#### Ma tr·∫≠n ph·∫£n chi·∫øu qua tr·ª•c y:

$$
R=\begin{bmatrix}-1&0\cr 0&1\end{bmatrix}
$$

{% tabs %}
{% tab title="Pytorch" %}
```python
import torch


reflection_matrix_x = torch.tensor([[1, 0], [0, -1]])
vector = torch.tensor([1, 1], dtype=torch.float32)
reflected_vector = torch.matmul(reflection_matrix_x, vector)

print(reflected_vector)
```
{% endtab %}

{% tab title="Numpy" %}
```python
import numpy as np
reflection_matrix_y = np.array([[-1, 0], [0, 1]])
vector = np.array([1, 1])
reflected_vector = np.dot(reflection_matrix_y, vector)
print(reflected_vector)
```
{% endtab %}
{% endtabs %}

### 2.4 Ph√©p chuy·ªÉn v·ªã

#### Ph√©p chuy·ªÉn v·ªã

Ph√©p chuy·ªÉn v·ªã c·ªßa m·ªôt ma tr·∫≠n l√† thao t√°c ƒë·∫£o ƒë·ªïi h√†ng th√†nh c·ªôt v√† ng∆∞·ª£c l·∫°i. ƒê·ªëi v·ªõi m·ªôt ma tr·∫≠n $A$ c√≥ k√≠ch th∆∞·ªõc $m \times n$, ma tr·∫≠n chuy·ªÉn v·ªã $A^T$ s·∫Ω c√≥ k√≠ch th∆∞·ªõc $n \times m$, v·ªõi ph·∫ßn t·ª≠ t·∫°i h√†ng $i$ v√† c·ªôt $j$ c·ªßa $A$ ƒë∆∞·ª£c chuy·ªÉn th√†nh ph·∫ßn t·ª≠ t·∫°i h√†ng $j$ v√† c·ªôt $i$ c·ªßa $A^T$. Ph√©p chuy·ªÉn v·ªã th∆∞·ªùng ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ bi·∫øn ƒë·ªïi kh√¥ng gian v√† gi·∫£i quy·∫øt c√°c b√†i to√°n tuy·∫øn t√≠nh.

{% tabs %}
{% tab title="Pytorch" %}
<pre class="language-python"><code class="lang-python"><strong>import torch
</strong><strong>
</strong><strong>translation_matrix_torch = torch.tensor([[1, 0, 2],
</strong>                                         [0, 1, 3],
                                         [0, 0, 1]])
vector_torch = torch.tensor([1, 1, 1], dtype=torch.float32)
translated_vector_torch = torch.matmul(translation_matrix_torch, vector_torch)

print("PyTorch Translated Vector:\n", translated_vector_torch)
</code></pre>
{% endtab %}

{% tab title="Numpy" %}
```python
import numpy as np

translation_matrix = np.array([[1, 0, 2],  # Translate by (2, 3)
                                [0, 1, 3],
                                [0, 0, 1]])
vector = np.array([1, 1, 1])  # Homogeneous coordinates
translated_vector = np.dot(translation_matrix, vector)

print("NumPy Translated Vector:\n", translated_vector)
```
{% endtab %}
{% endtabs %}

***

## 3. T·ªï h·ª£p c√°c ph√©p bi·∫øn ƒë·ªïi

T·ªï h·ª£p c√°c ph√©p bi·∫øn ƒë·ªïi l√† qu√° tr√¨nh √°p d·ª•ng nhi·ªÅu ph√©p bi·∫øn ƒë·ªïi li√™n ti·∫øp tr√™n m·ªôt ƒë·ªëi t∆∞·ª£ng ho·∫∑c kh√¥ng gian. Trong to√°n h·ªçc v√† khoa h·ªçc m√°y t√≠nh, c√°c ph√©p bi·∫øn ƒë·ªïi th∆∞·ªùng ƒë∆∞·ª£c bi·ªÉu di·ªÖn b·∫±ng ma tr·∫≠n v√† t·ªï h·ª£p c√°c ph√©p bi·∫øn ƒë·ªïi l√† nh√¢n c√°c ma tr·∫≠n t∆∞∆°ng ·ª©ng.

> K·∫øt h·ª£p c√°c ph√©p bi·∫øn ƒë·ªïi b·∫±ng c√°ch nh√¢n c√°c ma tr·∫≠n t∆∞∆°ng ·ª©ng.

#### V√≠ D·ª• C√°c T·ªï H·ª£p Th∆∞·ªùng D√πng

1. **Ph√©p T·ªãnh Ti·∫øn v√† Ph√©p Quay**: T·ªãnh ti·∫øn m·ªôt ƒëi·ªÉm trong kh√¥ng gian r·ªìi quay n√≥ quanh m·ªôt tr·ª•c c·ªë ƒë·ªãnh.
2. **Ph√©p Co Gi√£n v√† Ph√©p T·ªãnh Ti·∫øn**: Co gi√£n m·ªôt h√¨nh theo m·ªôt tr·ª•c nh·∫•t ƒë·ªãnh, sau ƒë√≥ di chuy·ªÉn n√≥ ƒë·∫øn m·ªôt v·ªã tr√≠ kh√°c.
3. **Ph√©p ƒê·ªëi X·ª©ng v√† Ph√©p Quay**: ƒê·ªëi x·ª©ng m·ªôt h√¨nh qua m·ªôt tr·ª•c tr∆∞·ªõc khi quay n√≥ quanh m·ªôt ƒëi·ªÉm c·ªë ƒë·ªãnh.

Vi·ªác k·∫øt h·ª£p c√°c ph√©p bi·∫øn ƒë·ªïi n√†y cho ph√©p linh ho·∫°t trong vi·ªác ƒëi·ªÅu ch·ªânh v√† th·ªÉ hi·ªán c√°c ƒë·ªëi t∆∞·ª£ng trong kh√¥ng gian kh√°c nhau, ƒë·∫∑c bi·ªát quan tr·ªçng trong lƒ©nh v·ª±c ƒë·ªì h·ªça m√°y t√≠nh v√† th·ªã gi√°c m√°y.

## 4. Ma tr·∫≠n Jacob v√† bi·∫øn ƒë·ªïi kh√¥ng gian

Ma tr·∫≠n Jacob, hay c√≤n g·ªçi l√† Jacobian, l√† m·ªôt ma tr·∫≠n ch·ª©a c√°c ƒë·∫°o h√†m ri√™ng ph·∫ßn c·ªßa m·ªôt h√†m nhi·ªÅu bi·∫øn. Trong to√°n h·ªçc, ma tr·∫≠n Jacob l√† c√¥ng c·ª• quan tr·ªçng ƒë·ªÉ ph√¢n t√≠ch v√† gi·∫£i quy·∫øt c√°c b√†i to√°n li√™n quan ƒë·∫øn ƒë·∫°o h√†m trong kh√¥ng gian nhi·ªÅu chi·ªÅu. N√≥ ƒë√≥ng vai tr√≤ ch·ªß ch·ªët trong vi·ªác t√≠nh to√°n t·ªëc ƒë·ªô thay ƒë·ªïi c·ªßa m·ªôt h√†m khi c√°c bi·∫øn ƒë·∫ßu v√†o thay ƒë·ªïi.

C√¥ng th·ª©c t·ªïng qu√°t c·ªßa ma tr·∫≠n Jacob cho m·ªôt h√†m vector $$\mathbf{F}: \mathbb{R}^n \to \mathbb{R}^m$$ , v·ªõi $$\mathbf{F}(x_1, x_2, ..., x_n) = [f_1(x_1, x_2, ..., x_n), f_2(x_1, x_2, ..., x_n), ..., f_m(x_1, x_2, ..., x_n)]$$ \
ƒë∆∞·ª£c bi·ªÉu di·ªÖn nh∆∞ sau:

$$
J = \begin{bmatrix} \frac{\partial f_1}{\partial x_1} & \frac{\partial f_1}{\partial x_2} & \cdots & \frac{\partial f_1}{\partial x_n} \ \frac{\partial f_2}{\partial x_1} & \frac{\partial f_2}{\partial x_2} & \cdots & \frac{\partial f_2}{\partial x_n} \ \vdots & \vdots & \ddots & \vdots \ \frac{\partial f_m}{\partial x_1} & \frac{\partial f_m}{\partial x_2} & \cdots & \frac{\partial f_m}{\partial x_n} \end{bmatrix}
$$

{% tabs %}
{% tab title="Pytorch" %}
```python
import pytorch

# PyTorch: T√≠nh Jacobi
inputs_torch = torch.tensor([1.0, 2.0], requires_grad=True)
output = torch.tensor([inputs_torch[0]**2 + inputs_torch[1], inputs_torch[1]**2 + inputs_torch[0]])
jacobi_matrix_torch = torch.autograd.functional.jacobian(lambda x: torch.tensor([x[0]**2 + x[1], x[1]**2 + x[0]]), inputs_torch)

print("\nPyTorch Jacobi Matrix:\n", jacobi_matrix_torch)
```
{% endtab %}

{% tab title="Second Tab" %}
```python
import numpy as np

def jacobian(func, inputs):
    n = len(inputs)
    jac = np.zeros((n, n))
    epsilon = 1e-5
    for i in range(n):
        perturbed = inputs.copy()
        perturbed[i] += epsilon
        jac[:, i] = (func(perturbed) - func(inputs)) / epsilon
    return jac

func = lambda x: np.array([x[0]**2 + x[1], x[1]**2 + x[0]])
inputs = np.array([1.0, 2.0])
jacobi_matrix = jacobian(func, inputs)
print("NumPy Jacobi Matrix:\n", jacobi_matrix)
```


{% endtab %}
{% endtabs %}



Ma tr·∫≠n Jacob r·∫•t quan tr·ªçng trong nhi·ªÅu lƒ©nh v·ª±c ·ª©ng d·ª•ng, bao g·ªìm t·ªëi ∆∞u h√≥a, ph√¢n t√≠ch ƒë·ªô ·ªïn ƒë·ªãnh v√† trong c√°c ph∆∞∆°ng ph√°p gi·∫£i h·ªá ph∆∞∆°ng tr√¨nh phi tuy·∫øn t√≠nh.

















